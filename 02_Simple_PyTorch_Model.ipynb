{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb85bb-c550-429d-aa88-ed15f86a5cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = models.resnet50(pretrained = True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = Model().eval().cuda()\n",
    "\n",
    "import json\n",
    "\n",
    "with open('./imagenet-simple-labels.json') as file:\n",
    "    labels = json.load(file)\n",
    "\n",
    "print(labels[:5])\n",
    "\n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open('./assets/goldfish.jpg')\n",
    "\n",
    "#displays image of a goldfish\n",
    "#image\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.485, 0.456, 0.406]\n",
    "\n",
    "resize = transforms.Resize((256, 256))\n",
    "center_crop = transforms.CenterCrop(224)\n",
    "to_tensor = transforms.ToTensor()\n",
    "normalize = transforms.Normalize(mean = imagenet_mean,\n",
    "                                std = imagenet_std)\n",
    "\n",
    "transform = transforms.Compose([resize, center_crop, to_tensor, normalize])\n",
    "\n",
    "image_tensor = transform(image).unsqueeze(0).cuda()\n",
    "logits = model(image_tensor)\n",
    "\n",
    "K = 3\n",
    "values, indices = torch.topk(logits, K)\n",
    "\n",
    "values = values.detach().tolist()[0]\n",
    "indices = indices.detach().tolist()[0]\n",
    "\n",
    "for i in range(K):\n",
    "    print(values[i], indices[i], labels[indices[i]])\n",
    "\n",
    "class PyTorch_to_TorchScript(nn.Module):\n",
    "    def __init__(self, my_model):\n",
    "        super(PyTorch_to_TorchScript, self).__init__()\n",
    "        self.model = my_model.model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "torchscript_model = PyTorch_to_TorchScript(model).eval().cuda()\n",
    "traced_script_module = torch.jit.script(torchscript_model)\n",
    "traced_script_module.save('./models/simple-pytorch-model/1/model.pt')\n",
    "\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 224, 224).cuda()\n",
    "\n",
    "input_names = ['actual_input_1'] + ['learned_%d' % i for i in range(16)]\n",
    "output_names = ['output1']\n",
    "\n",
    "torch.onnx.export(model, dummy_input,\n",
    "                 'models/simple-onnx-model/1/model.onnx', verbose=False,\n",
    "                 input_names = input_names, output_names = output_names,\n",
    "                 dynamic_axes={'actual_input_1': {0: 'batch_size'}, 'output1': {0: 'batch_size'}})\n",
    "\n",
    "configuration = \"\"\"\n",
    "name: \"simple-pytorch-model\"\n",
    "platform: \"pytorch_libtorch\"\n",
    "max_batch_size: 32\n",
    "input [\n",
    " {\n",
    "     name: \"input__0\"\n",
    "     data_type: TYPE_FP32\n",
    "     format: FORMAT_NCHW\n",
    "     dims: [3, 224, 224]\n",
    " }\n",
    "]\n",
    "output {\n",
    "    name: \"output__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1000 ]\n",
    "  }\n",
    "\"\"\"\n",
    "\n",
    "with open('models/simple-pytorch-model/config.pbtxt', 'w') as file:\n",
    "    file.write(configuration)\n",
    "\n",
    "configuration = \"\"\"\n",
    "name: \"simple-onnx-model\"\n",
    "platform: \"onnxruntime_onnx\"\n",
    "max_batch_size: 32\n",
    "input [\n",
    " {\n",
    "    name: \"actual_input_1\"\n",
    "    data_type: TYPE_FP32\n",
    "    format: FORMAT_NCHW\n",
    "    dims: [ 3, 224, 224 ]\n",
    "  }\n",
    "]\n",
    "output {\n",
    "    name: \"output1\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1000]\n",
    "  }\n",
    "\"\"\"\n",
    "\n",
    "with open('models/simple-onnx-model/config.pbtxt', 'w') as file:\n",
    "    file.write(configuration)\n",
    "    \n",
    "\n",
    "import tritonclient.http as tritonhttpclient\n",
    "VERBOSE = False\n",
    "input_name = 'input__0'\n",
    "input_shape = (1, 3, 224, 224)\n",
    "input_dtype = 'FP32'\n",
    "output_name = 'output__0'\n",
    "model_name = 'simple-pytorch-model'\n",
    "url = 'triton:8000'\n",
    "model_version = '1'\n",
    "\n",
    "triton_client = tritonhttpclient.InferenceServerClient(url=url, verbose=VERBOSE)\n",
    "model_metadata = triton_client.get_model_metadata(model_name=model_name, model_version=model_version)\n",
    "model_config = triton_client.get_model_config(model_name=model_name, model_version=model_version)\n",
    "\n",
    "image_numpy = image_tensor.cpu().numpy()\n",
    "print(image_numpy.shape)\n",
    "\n",
    "input0 = tritonhttpclient.InferInput(input_name, input_shape, input_dtype)\n",
    "input0.set_data_from_numpy(image_numpy, binary_data=False)\n",
    "\n",
    "output = tritonhttpclient.InferRequestedOutput(output_name, binary_data=False)\n",
    "response = triton_client.infer(model_name, model_version=model_version,\n",
    "                              inputs=[input0], outputs=[output])\n",
    "\n",
    "logits = response.as_numpy(output_name)\n",
    "logits = np.asarray(logits, dtype=np.float32)\n",
    "print(logits.shape)\n",
    "print(labels[np.argmax(logits)])\n",
    "\n",
    "\n",
    "VERBOSE = False\n",
    "input_name = 'actual_input_1'\n",
    "input_shape = (1, 3, 224, 224)\n",
    "input_dtype = 'FP32'\n",
    "output_name = 'output1'\n",
    "model_name = 'simple-onnx-model'\n",
    "url = 'triton:8000'\n",
    "model_version = '1'\n",
    "\n",
    "triton_client = tritonhttpclient.InferenceServerClient(url=url, verbose=VERBOSE)\n",
    "model_metadata = triton_client.get_model_metadata(model_name=model_name, model_version=model_version)\n",
    "model_config = triton_client.get_model_config(model_name=model_name, model_version=model_version)\n",
    "\n",
    "image_numpy = image_tensor.cpu().numpy()\n",
    "print(image_numpy.shape)\n",
    "\n",
    "input0 = tritonhttpclient.InferInput(input_name, input_shape, input_dtype)\n",
    "input0.set_data_from_numpy(image_numpy, binary_data=False)\n",
    "\n",
    "output = tritonhttpclient.InferRequestedOutput(output_name, binary_data=False)\n",
    "response = triton_client.infer(model_name, model_version=model_version,\n",
    "                              inputs=[input0], outputs=[output])\n",
    "\n",
    "logits = response.as_numpy(output_name)\n",
    "logits = np.asarray(logits, dtype=np.float32)\n",
    "\n",
    "print(labels[np.argmax(logits)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32bf43-7029-4842-b16b-747e96dc5bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
